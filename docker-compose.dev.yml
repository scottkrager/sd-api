services:
  nginx:
    image: nginx:1.25-alpine
    ports:
      - "127.0.0.1:5050:80"
    volumes:
      - ./docker/nginx:/etc/nginx/conf.d:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - sd-api
    networks:
      - sd-network

  sd-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.dev
    expose:
      - "5000"
    volumes:
      - ./app:/src/app:ro
      - ./generated_images:/src/generated_images
      - ./logs/sd-api:/src/logs
      - model_cache:/root/.cache/huggingface
      - ./gunicorn.conf.py:/src/gunicorn.conf.py:ro
    environment:
      - MODEL_ID=stabilityai/stable-diffusion-3.5-large
      - NUM_WORKERS=1
      - PYTORCH_ENABLE_MPS_FALLBACK=1
      - LOG_LEVEL=debug
      - PYTHONPATH=/src
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - HF_HOME=/root/.cache/huggingface
      - HF_TOKEN=${HF_TOKEN}
      - PYTHONUNBUFFERED=1
    networks:
      - sd-network
    restart: unless-stopped
    shm_size: 1gb
    command: gunicorn --config /src/gunicorn.conf.py app.app:app

networks:
  sd-network:
    driver: bridge

volumes:
  model_cache: